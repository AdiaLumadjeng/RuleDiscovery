{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule Discovery with RUX and RUG\n",
    "\n",
    "In this short note, we use two standard datasets to demonstrate how to use Rule Extractor (RUX) and the rule generator (RUG) algorithms. First we start with importing the necessary packages that we will use in this note. Note that both RUX and RUG are imported from `rulediscovery`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Datasets as DS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from rulediscovery import RUXClassifier, RUGClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeds Dataset\n",
    "\n",
    "You can find this dataset and its description on [this page](https://archive.ics.uci.edu/ml/datasets/seeds). This dataset has 210 samples with seven features and three classes. The very last column of the dataframe gives the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  210\n",
      "number of features:  7\n",
      "Number of classes:  3\n"
     ]
    }
   ],
   "source": [
    "df = np.array(DS.seeds('datasets/'))\n",
    "X = df[:, 0:-1]\n",
    "y = df[:, -1]\n",
    "print('Number of samples: ', len(y))\n",
    "print('number of features: ', len(X[0,:]))\n",
    "print('Number of classes: ', len(np.unique(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use RUX for interpretation, we first train a Random Forest model and an AdaBoost model. The depth of the trees in both ensemble methods are set to three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepth = 3\n",
    "\n",
    "# Random Forest\n",
    "RF = RandomForestClassifier(max_depth=maxDepth)\n",
    "RF_fit = RF.fit(X, y)\n",
    "RF_pred = RF_fit.predict(X)\n",
    "\n",
    "# AdaBoost\n",
    "ADA = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', base_estimator=DecisionTreeClassifier(max_depth=maxDepth))\n",
    "ADA_fit = ADA.fit(X, y)\n",
    "ADA_pred = ADA_fit.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use RUX to discover the most prominent rules within each ensemble for interpretation. Note that RUX works with a trained model. In its current version, RUX admits either a trained Random Forest model with the parameter `rf` or a trained AdaBoost model with the parameter `ada`. While interpreting the trained Random Forest model, we use the rule length as a cost parameter. Likewise, for the trained AdaBoost model, we use the inverse of the tree weights in the ensemble (the higher the weight of a tree, the less the cost of the rule coming from that tree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleLengthCost = True\n",
    "useAdaWeights = True\n",
    "\n",
    "#RUXRF\n",
    "RUXRF = RUXClassifier(rf=RF_fit, rule_length_cost=ruleLengthCost)\n",
    "RUXRF_fit = RUXRF.fit(X, y)\n",
    "RUXRF_pred = RUXRF.predict(X)\n",
    "\n",
    "#RUXADA\n",
    "RUXADA = RUXClassifier(ada=ADA_fit, use_ada_weights=useAdaWeights)\n",
    "RUXADA_fit = RUXADA.fit(X, y)\n",
    "RUXADA_pred = RUXADA.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our second algorithm RUG itself is a classifier that can be trained like other learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUG\n",
    "RUG = RUGClassifier(max_depth=maxDepth, rule_length_cost=ruleLengthCost)\n",
    "RUG_fit = RUG.fit(X, y)\n",
    "RUG_pred = RUG.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the accuracies that we obtain with all algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Accuracy Scores ##\n",
      "Random Forest:  0.9428571428571428\n",
      "AdaBoost:  1.0\n",
      "RUXRF:  1.0\n",
      "RUXADA:  1.0\n",
      "RUG:  0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "print('## Accuracy Scores ##')\n",
    "print('Random Forest: ', accuracy_score(RF_pred, y))\n",
    "print('AdaBoost: ', accuracy_score(ADA_pred, y)) \n",
    "print('RUXRF: ', accuracy_score(RUXRF_pred, y))\n",
    "print('RUXADA: ', accuracy_score(RUXADA_pred, y))\n",
    "print('RUG: ', accuracy_score(RUG_pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we obtain quite good accuracies with all the methods. Let's see the total number of rules each method produces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Number of Rules ##\n",
      "Random Forest:  691\n",
      "AdaBoost:  744\n",
      "RUXRF:  21\n",
      "RUXADA:  28\n",
      "RUG:  9\n"
     ]
    }
   ],
   "source": [
    "print('## Number of Rules ##')\n",
    "print('Random Forest: ', RUXRF.getInitNumOfRules())\n",
    "print('AdaBoost: ', RUXADA.getInitNumOfRules())\n",
    "print('RUXRF: ', RUXRF.getNumOfRules())\n",
    "print('RUXADA: ', RUXADA.getNumOfRules())\n",
    "print('RUG: ', RUG.getNumOfRules())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUX and RUG models produce significantly less number of rules than the ensemble methods. \n",
    "\n",
    "So far, we have used the entire dataset for training. Let's get a glimpse of the generalization performances of the above methods. To serve this purpose, we split the data into train-test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Accuracy Scores ##\n",
      "Random Forest:  0.8412698412698413\n",
      "AdaBoost:  0.9523809523809523\n",
      "RUXRF:  0.9047619047619048\n",
      "RUXADA:  0.9206349206349206\n",
      "RUG:  0.9206349206349206\n",
      "\n",
      "## Number of Rules ##\n",
      "Random Forest:  614\n",
      "AdaBoost:  742\n",
      "RUXRF:  19\n",
      "RUXADA:  20\n",
      "RUG:  24\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Random Forest\n",
    "RF = RandomForestClassifier(max_depth=maxDepth)\n",
    "RF_fit = RF.fit(X_train, y_train)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "\n",
    "# AdaBoost\n",
    "ADA = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', base_estimator=DecisionTreeClassifier(max_depth=maxDepth))\n",
    "ADA_fit = ADA.fit(X_train, y_train)\n",
    "ADA_pred = ADA_fit.predict(X_test)\n",
    "\n",
    "#RUXRF\n",
    "RUXRF = RUXClassifier(rf=RF_fit, rule_length_cost=ruleLengthCost)\n",
    "RUXRF_fit = RUXRF.fit(X_train, y_train)\n",
    "RUXRF_pred = RUXRF.predict(X_test)\n",
    "\n",
    "#RUXADA\n",
    "RUXADA = RUXClassifier(ada=ADA_fit, use_ada_weights=useAdaWeights)\n",
    "RUXADA_fit = RUXADA.fit(X_train, y_train)\n",
    "RUXADA_pred = RUXADA.predict(X_test)\n",
    "\n",
    "#RUG\n",
    "RUG = RUGClassifier(max_depth=maxDepth)\n",
    "RUG_fit = RUG.fit(X_train, y_train)\n",
    "RUG_pred = RUG.predict(X_test)\n",
    "\n",
    "print('## Accuracy Scores ##')\n",
    "print('Random Forest: ', accuracy_score(RF_pred, y_test))\n",
    "print('AdaBoost: ', accuracy_score(ADA_pred, y_test)) \n",
    "print('RUXRF: ', accuracy_score(RUXRF_pred, y_test))\n",
    "print('RUXADA: ', accuracy_score(RUXADA_pred, y_test))\n",
    "print('RUG: ', accuracy_score(RUG_pred, y_test))\n",
    "\n",
    "print('\\n## Number of Rules ##')\n",
    "print('Random Forest: ', RUXRF.getInitNumOfRules())\n",
    "print('AdaBoost: ', RUXADA.getInitNumOfRules())\n",
    "print('RUXRF: ', RUXRF.getNumOfRules())\n",
    "print('RUXADA: ', RUXADA.getNumOfRules())\n",
    "print('RUG: ', RUG.getNumOfRules())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the discovered rules. Here are the **first five** rules sorted in descending order of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RULE 0:\n",
      "4.79 < x[6] <= 5.60\n",
      "x[0] <= 13.11\n",
      "\n",
      "Class: 2\n",
      "Scaled rule weight: 1.0000\n",
      "\n",
      "RULE 1:\n",
      "2.50 < x[5] <= 4.49\n",
      "x[0] > 15.24\n",
      "\n",
      "Class: 1\n",
      "Scaled rule weight: 0.5171\n",
      "\n",
      "RULE 2:\n",
      "x[4] <= 3.53\n",
      "x[5] <= 3.57\n",
      "\n",
      "Class: 0\n",
      "Scaled rule weight: 0.4156\n",
      "\n",
      "RULE 3:\n",
      "x[2] <= 0.90\n",
      "x[6] > 5.14\n",
      "x[1] > 13.73\n",
      "\n",
      "Class: 1\n",
      "Scaled rule weight: 0.4099\n",
      "\n",
      "RULE 4:\n",
      "x[0] <= 13.65\n",
      "x[4] > 2.94\n",
      "\n",
      "Class: 2\n",
      "Scaled rule weight: 0.3934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RUG.printRules(indices=range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banknote Dataset\n",
    "\n",
    "The details of this dataset are given on [this page](https://archive.ics.uci.edu/ml/datasets/banknote+authentication). There are 1,372 samples with four features. Each sample is labeled as a genuine or a forged banknote (binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(DS.banknote('datasets/'))\n",
    "X = df[:, 0:-1]\n",
    "y = df[:, -1]\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)    \n",
    "\n",
    "maxDepth = 3\n",
    "\n",
    "# Random Forest\n",
    "RF = RandomForestClassifier(max_depth=3)\n",
    "RF_fit = RF.fit(X_train, y_train)\n",
    "RF_pred = RF_fit.predict(X_test)\n",
    "\n",
    "# AdaBoost\n",
    "ADA = AdaBoostClassifier(n_estimators=100, algorithm='SAMME', base_estimator=DecisionTreeClassifier(max_depth=3))\n",
    "ADA_fit = ADA.fit(X_train, y_train)\n",
    "ADA_pred = ADA_fit.predict(X_test)\n",
    "\n",
    "#RUXRF\n",
    "RUXRF = RUXClassifier(rf=RF_fit, rule_length_cost=ruleLengthCost)\n",
    "RUXRF_fit = RUXRF.fit(X_train, y_train)\n",
    "RUXRF_pred = RUXRF.predict(X_test)\n",
    "\n",
    "#RUXADA\n",
    "RUXADA = RUXClassifier(ada=ADA_fit, use_ada_weights=useAdaWeights)\n",
    "RUXADA_fit = RUXADA.fit(X_train, y_train)\n",
    "RUXADA_pred = RUXADA.predict(X_test)\n",
    "\n",
    "#RUG\n",
    "RUG = RUGClassifier(max_depth=maxDepth, rule_length_cost=ruleLengthCost)\n",
    "RUG_fit = RUG.fit(X_train, y_train)\n",
    "RUG_pred = RUG.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Accuracy Scores ##\n",
      "Random Forest:  0.9223300970873787\n",
      "AdaBoost:  0.9951456310679612\n",
      "RUXRF:  0.9854368932038835\n",
      "RUXADA:  0.9902912621359223\n",
      "RUG:  0.9878640776699029\n",
      "\n",
      "## Number of Rules ##\n",
      "Random Forest:  715\n",
      "AdaBoost:  757\n",
      "RUXRF:  25\n",
      "RUXADA:  43\n",
      "RUG:  13\n"
     ]
    }
   ],
   "source": [
    "print('## Accuracy Scores ##')\n",
    "print('Random Forest: ', accuracy_score(RF_pred, y_test))\n",
    "print('AdaBoost: ', accuracy_score(ADA_pred, y_test)) \n",
    "print('RUXRF: ', accuracy_score(RUXRF_pred, y_test))\n",
    "print('RUXADA: ', accuracy_score(RUXADA_pred, y_test))\n",
    "print('RUG: ', accuracy_score(RUG_pred, y_test))\n",
    "\n",
    "print('\\n## Number of Rules ##')\n",
    "print('Random Forest: ', RUXRF.getInitNumOfRules())\n",
    "print('AdaBoost: ', RUXADA.getInitNumOfRules())\n",
    "print('RUXRF: ', RUXRF.getNumOfRules())\n",
    "print('RUXADA: ', RUXADA.getNumOfRules())\n",
    "print('RUG: ', RUG.getNumOfRules())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although RUG discovers 13 rules, we can look at the **first ten rules** sorted in terms of their weights. Using these these ten rules, we can also check how would the accuracy have changed, if we had constructed different subsets in a nested manner by adding one more rule each time. Note that the `predict` function of RUG can also be used with only a subset of the discovered rules (see the comment in the below code snippet). This construction allows us to give an _interpretation plot_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "selectedRuleNum = 10 \n",
    "\n",
    "weights = np.round(RUG.getWeights()[:selectedRuleNum], decimals=2)\n",
    "accuracies = []\n",
    "coverages = []\n",
    "\n",
    "for indx in range(min(selectedRuleNum, RUG.getNumOfRules())):\n",
    "    # Use only the first indx+1 many rules for prediction\n",
    "    RUG_pred_test = RUG.predict(X_test, range(indx+1))\n",
    "    accuracies.append(accuracy_score(RUG_pred_test, y_test))\n",
    "    coverages.append(RUG.getNumOfMissed())\n",
    "    \n",
    "accuracies = np.round(accuracies, decimals=3)\n",
    "coverages = np.round(1.0-(np.array(coverages)/len(y)), decimals=2)*100\n",
    "coverages = np.round(coverages, decimals=1)\n",
    "txtmisses = [str(cover)+'%' for cover in coverages]\n",
    "\n",
    "\n",
    "# Plotting\n",
    "data = {'Rules': [indx+1 for indx in range(len(accuracies))],\n",
    "        'Weights': weights,\n",
    "        'Coverages': coverages,\n",
    "        'Accuracies': accuracies}\n",
    "\n",
    "df = pd.DataFrame(data, columns=data.keys())\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "sns.color_palette('pastel')\n",
    "\n",
    "bars = sns.barplot(data=df, x='Rules', y=weights, ax=ax1, \n",
    "                   color='green', alpha=0.3)\n",
    "\n",
    "for indx, txtmiss in enumerate(txtmisses):\n",
    "    bars.annotate(txtmiss, xy=(indx, weights[indx]+0.02), \n",
    "                  color='purple', horizontalalignment='center',\n",
    "                  fontsize=8)\n",
    "\n",
    "bars.axhline(1.0, color='lightgray', linestyle='--')\n",
    "    \n",
    "ax1.set_ylabel('Rule Weight', color='darkgreen')\n",
    "ax1.set_ylim([0.0, 1.1])\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "sns.pointplot(data=df, x='Rules', y='Accuracies', ax=ax2)\n",
    "ax2.set_ylabel('Accuracy', color='darkblue')\n",
    "ax2.set_ylim(ax1.get_ylim())\n",
    "ax2.grid(False)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interpretation plot shows that RUG reaches a high accuracy with the first 10 rules that are ordered in terms of their normalized weights (bar heights). The percentages show the\n",
    "cumulative fractions of the samples covered after adding each rule."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
